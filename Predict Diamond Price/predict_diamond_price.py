# -*- coding: utf-8 -*-
"""predict diamond price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fezrjJ764Xg5XnQwY1fOI55FC8_mYqXd
"""

import pandas as pd
import numpy as np

url='https://raw.githubusercontent.com/Fuad3004/Data_Science_with_python/main/Predict%20Diamond%20Price/Diamon%20Price.csv'
df = pd.read_csv(url)
df.head()

"""#EDA"""

df.describe()

df.corr()

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(df.corr(),annot=True);

"""#Feature Engineering"""

df['symmetry'] = df['x']/df['y']
df.head()

df = df.dropna(axis=0)

df_trans=pd.get_dummies(df)
X = df_trans.drop(['price','x','y','z'],axis=1)
y=df_trans['price']
features = X.columns

plt.figure(figsize=(20,10))
sns.heatmap(df_trans.corr(),annot=True);

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import  LinearRegression, Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.metrics import mean_squared_error

#scale the data
s = StandardScaler()
X = s.fit_transform(X)

X

X_train,X_test,y_train,y_test = train_test_split(X,y)

models_eval = pd.DataFrame(index=['Null','KNN','MLR'],columns=['RMSE'])

ypred_null = y_train.mean()

ypred_null

"""#K-Neighbours Regressor"""

knn = KNeighborsRegressor(n_neighbors=7)
knn.fit(X_train,y_train)

KNeighborsRegressor(n_neighbors=7)

y_pred = knn.predict(X_test)

y_pred

"""#Random Forrest Regression"""

rf = RandomForestRegressor(n_estimators=10)
rf.fit(X_train,y_train)
y_pred2=y_pred = rf.predict(X_test)

y_pred2

"""#Linear Regression"""

lin = LinearRegression()
lin = lin.fit(X_train,y_train)
y_pred3 = lin.predict(X_test)

"""#Lasso Regression"""

lasso = Lasso()
lasso.fit(X_train,y_train)
y_pred4 = lasso.predict(X_test)

"""#RESULT"""

model_eval=pd.DataFrame(index=['KNN','MLR'],columns=['RMSE'])
model_eval.loc['KNN','RMSE']=np.sqrt(mean_squared_error(y_test,y_pred))
model_eval.loc['RF','RMSE'] = np.sqrt(mean_squared_error(y_test,y_pred2))
model_eval.loc['MLR','RMSE'] = np.sqrt(mean_squared_error(y_test,y_pred3))
model_eval.loc['Lasso','RMSE'] = np.sqrt(mean_squared_error(y_test,y_pred4))
model_eval.loc['NULL','RMSE'] = ypred_null
model_eval

fig, ax = plt.subplots(figsize=(12,8))
ax.scatter(y_test,y_pred,s=1)
ax.plot(y_test,y_test,color='red')

sns.distplot(y_pred-y_test)

lin=LinearRegression()
lin.fit(X_train,y_train)
y_pred2 = lin.predict(X_test)
model_eval.loc['MLR','RMSE']=np.sqrt(mean_squared_error(y_pred2,y_test))

#features importance
from sklearn.ensemble import ExtraTreesRegressor
model =ExtraTreesRegressor()
model.fit(X,y)

ExtraTreesRegressor()

model.feature_importances_.tolist()